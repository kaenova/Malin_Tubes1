{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembelajaran Mesin: Tugas Besar 1\n",
    "\n",
    "Kaenova Mahendra Auditama  \n",
    "IF-43-02  \n",
    "1301190324  \n",
    "  \n",
    "Pada kodingan ini, saya mencoba untuk membuat sebuah model yang akan digunakan untuk membuat cluster pada suatu data. Data yang diberikan merupakan data ketertarikan pelanggan untuk membeli kendaraan baru. Pada akhirnya, saya menggunakan algoritma k-means karena kami diminta untuk membuat model dalam bentuk unsupervised learning\n",
    "  \n",
    "  \n",
    "<sup>\\*runs on AI Lab computer</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from urllib.request import urlopen\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansBefore:\n",
    "  training_arr = None\n",
    "  point = None\n",
    "  inertia = None\n",
    "  \n",
    "  def __init__(self, df: pd.DataFrame):\n",
    "    '''\n",
    "    Kelas ini digunakan untuk menyiapkan dataframe yang akan ditraining.\n",
    "    Pastikan kolom bernama id atau sejenis sudah di drop tidak termasuk ke dalam dataframe.\n",
    "    '''\n",
    "    print(\"K-Means akan ditentukan oleh atribut-atribut di bawah ini:\")\n",
    "    print(\"[\", end=\"\")\n",
    "    for i in range(len(df.columns)):\n",
    "      print(df.columns[i] + \" \", end=\"\")\n",
    "    print(\"]\", end=\"\\n\")\n",
    "    self.training_arr = df.to_numpy()\n",
    "    \n",
    "  def fit_predict(self, k_num:int = 3, max_step:int = 500, conv_threshold: float = 1e-5) -> np.array:\n",
    "    '''\n",
    "    Membuat model KMeans dengan K tertentu. Akan mengkembalikan hasil prediksi cluster.\n",
    "    Poin kluster akan disimpan pada variable point\n",
    "    '''\n",
    "    # Setting up cluster arry for every record\n",
    "    cluster = np.zeros(len(self.training_arr))\n",
    "    \n",
    "    # normalize data\n",
    "    data = self.__normalize_data__(self.training_arr)\n",
    "    \n",
    "    # Initialize centroid using KMeans++  \n",
    "    point = self.__initialize_centroids__(data, k_num)\n",
    "        \n",
    "    # Setup convergence and counter\n",
    "    convergence = False\n",
    "    step = 0 \n",
    "        \n",
    "    while not convergence and (step < max_step):\n",
    "      initial_point = point\n",
    "      distance = self.__calculate_distance__(data, point)\n",
    "      cluster = self.__clustering__(distance)\n",
    "      new_point = self.__point_nomralization__(data, point, cluster)\n",
    "      convergence = self.__convergence_check__(initial_point, new_point, conv_threshold)\n",
    "      \n",
    "      if convergence:\n",
    "        point = new_point\n",
    "        print(\"It's convergence!\")\n",
    "      else:\n",
    "        point = new_point\n",
    "        step += 1\n",
    "        print(\"STEP:\", step)\n",
    "      \n",
    "    \n",
    "    self.inertia = self.__calculate_inertia__(data, cluster, point)\n",
    "    self.point = self.__denormalize_point__(point, self.training_arr)\n",
    "    return cluster\n",
    "    \n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def get_cluster_centroid(self) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk mengambil point\n",
    "    '''\n",
    "    if type(self.point) == \"NoneType\":\n",
    "      print(\"Nothing returned, point not initialize. Try using fit_predict first.\")\n",
    "      return\n",
    "    return self.point\n",
    "  \n",
    "  \n",
    "  def __initialize_centroids__(self, data:np.array, k:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menginisialisasikan centroid. Menggunakan algoritma k-means++\n",
    "    referensi membantu: https://www.youtube.com/watch?v=HatwtJSsj5Q\n",
    "    '''\n",
    "    centroids = []\n",
    "    random.seed(1) # To get same random result for benchmark purposes\n",
    "    centroids.append( data[random.randrange(0, len(data))] )\n",
    "    \n",
    "    for i in range(1, k):\n",
    "      min_dist = []\n",
    "      for data_point in data:\n",
    "        distance_data_point = []\n",
    "        for point in centroids:\n",
    "          distance_data_point.append(np.linalg.norm(data_point - point))\n",
    "        min_dist.append(min(distance_data_point))\n",
    "      \n",
    "      probcum  = sum(min_dist)\n",
    "      prob_point = [value / probcum for value in min_dist]\n",
    "      \n",
    "      centroids.append(data[np.argmax(prob_point)])\n",
    "    \n",
    "    return np.array(centroids)\n",
    "  \n",
    "  \n",
    "  def __clustering__(self, distance: np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini akan mengembalikan hasil clustering berdasarkan distance\n",
    "    '''\n",
    "    cluster = np.zeros(len(distance))\n",
    "    for i in range(len(cluster)):\n",
    "      cluster[i] = np.argmin(distance[i])\n",
    "    return cluster\n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def __calculate_distance__(self, data:np.array, point: np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini akan menghitung setiap titik dengan point dan mengkembalikan jarak dari titik ke point\n",
    "    '''\n",
    "    distance = np.zeros((len(data), len(point)))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "      current_record = data[i]\n",
    "      for j in range(len(point)):\n",
    "        current_point = point[j]\n",
    "        # numpy eucledience distance\n",
    "        distance[i][j] = np.linalg.norm(current_point - current_record)\n",
    "    \n",
    "    return distance\n",
    "  \n",
    "  def __point_nomralization__(self, data:np.array, point:np.array, cluster:np.array) -> (np.array, np.array):\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menghitung ulang kembali point dengan rata-rata\n",
    "    '''\n",
    "    new_point = np.zeros((len(point), len(point[0])))\n",
    "    counter_array = np.zeros(len(point))\n",
    "    for i in range(len(cluster)):\n",
    "      new_point[int(cluster[i])] = new_point[int(cluster[i])] + data[i]\n",
    "      counter_array[int(cluster[i])] += 1\n",
    "      \n",
    "    unique_on_cluster = np.unique(cluster)\n",
    "    for i in range(len(point)):\n",
    "      # nan handling\n",
    "      if i not in unique_on_cluster:\n",
    "        new_point[i] = point[i]\n",
    "      else:\n",
    "        new_point[i] = np.true_divide(new_point[i], counter_array[i])\n",
    "      \n",
    "    return new_point\n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def __convergence_check__(self, points1: np.array, points2:np.array, threshold: float) -> bool:\n",
    "    '''\n",
    "    Fungsi ini untuk mengecek convergence berdasarkan threshold yang dibuat.\n",
    "    titik cluster pertama akan dibandingkan dengan titik cluster kedua.\n",
    "    note: maybe i should use euclediance distance insted of menghitung satu-satu\n",
    "    '''\n",
    "    local_convergence = False\n",
    "    normalize_threshold_positive, normalize_threshold_negative  = 1 + threshold, 1 - threshold\n",
    "    points_counter = 0\n",
    "    center = np.zeros(len(points1[0]))\n",
    "    for i in range(len(points1)):\n",
    "      current_first_point, current_second_point = points1[i], points2[i]\n",
    "      distance_first_point, distance_second_point = np.linalg.norm(current_first_point - center), np.linalg.norm(current_second_point - center)\n",
    "      distance_threshold_positive = distance_first_point * normalize_threshold_positive\n",
    "      distance_threshold_negative = distance_first_point * normalize_threshold_negative\n",
    "      if distance_threshold_positive > distance_second_point and distance_threshold_negative < distance_second_point:\n",
    "        points_counter += 1\n",
    "    \n",
    "    if points_counter == len(points1):\n",
    "      local_convergence = True\n",
    "    \n",
    "    return local_convergence\n",
    "  \n",
    "  def __calculate_inertia__(self, data:np.array, cluster:np.array, points:np.array) -> np.array:\n",
    "    '''\n",
    "    K-Means: Inertia\n",
    "    Inertia measures how well a dataset was clustered by K-Means. It is calculated by measuring the distance between each data point and its centroid, squaring this distance, and summing these squares across one cluster.\n",
    "    ref: https://towardsdatascience.com/clustering-how-to-find-hyperparameters-using-inertia-b0343c6fe819\n",
    "    '''\n",
    "    inertia = 0\n",
    "    for i in range(len(data)):\n",
    "      inertia += (np.linalg.norm(data[i] - points[int(cluster[i])]))**2\n",
    "      \n",
    "    return inertia\n",
    "  \n",
    "  def __normalize_data__(self, data:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menormalisasikan data dengan menggunakan min-max scaling. Sehingga data berjenis dan bersatuan apapun data diproses dengan baik.\n",
    "    '''\n",
    "    data = data.copy()\n",
    "    for i in range(len(data[0])):\n",
    "      col_arr = data[:,i]\n",
    "      minmax = MinMaxScaler()\n",
    "      normalize = minmax.fit_transform(col_arr.reshape(-1,1)).reshape(1,-1)\n",
    "      data[:, i] = normalize[0]\n",
    "      \n",
    "    return data\n",
    "  \n",
    "  def __denormalize_point__(self, data:np.array, original_data:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk mendenormalisasikan point-point yang sudah dihitung menggunakan data yang ternormalisasi\n",
    "    '''\n",
    "    for i in range(len(data[0])):\n",
    "      col_arr = data[:,i]\n",
    "      col_arr_ori = original_data[:, i]\n",
    "      \n",
    "      minimums = min(col_arr_ori)\n",
    "      maximums = max(col_arr_ori)\n",
    "      for j in range(len(col_arr)):\n",
    "        col_arr[j] = ((col_arr[j]*(maximums - minimums)) + minimums)\n",
    "      data[:, i] = col_arr\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "  training_arr = None\n",
    "  point = None\n",
    "  inertia = None\n",
    "  \n",
    "  def __init__(self, df: pd.DataFrame):\n",
    "    '''\n",
    "    Kelas ini digunakan untuk menyiapkan dataframe yang akan ditraining.\n",
    "    Pastikan kolom bernama id atau sejenis sudah di drop tidak termasuk ke dalam dataframe.\n",
    "    '''\n",
    "    print(\"K-Means akan ditentukan oleh atribut-atribut di bawah ini:\")\n",
    "    print(\"[\", end=\"\")\n",
    "    for i in range(len(df.columns)):\n",
    "      print(df.columns[i] + \" \", end=\"\")\n",
    "    print(\"]\", end=\"\\n\")\n",
    "    self.training_arr = df.to_numpy()\n",
    "    \n",
    "  def fit_predict(self, k_num:int = 3, max_step:int = 500, conv_threshold: float = 1e-5) -> np.array:\n",
    "    '''\n",
    "    Membuat model KMeans dengan K tertentu. Akan mengkembalikan hasil prediksi cluster.\n",
    "    Poin kluster akan disimpan pada variable point\n",
    "    '''\n",
    "    # Setting up cluster arry for every record\n",
    "    cluster = np.zeros(len(self.training_arr))\n",
    "    \n",
    "    # normalize data\n",
    "    data = self.__normalize_data__(self.training_arr)\n",
    "    \n",
    "    # Initialize centroid using KMeans++  \n",
    "    point = self.__initialize_centroids__(data, k_num)\n",
    "        \n",
    "    # Setup convergence and counter\n",
    "    convergence = False\n",
    "    step = 0 \n",
    "        \n",
    "    while not convergence and (step < max_step):\n",
    "      initial_point = point\n",
    "      distance = self.__calculate_distance__(data, point)\n",
    "      cluster = self.__clustering__(distance)\n",
    "      new_point = self.__point_nomralization__(data, point, cluster)\n",
    "      convergence = self.__convergence_check__(initial_point, new_point, conv_threshold)\n",
    "      \n",
    "      if convergence:\n",
    "        point = new_point\n",
    "        print(\"It's convergence!\")\n",
    "      else:\n",
    "        point = new_point\n",
    "        step += 1\n",
    "        print(\"STEP:\", step)\n",
    "      \n",
    "    \n",
    "    self.inertia = self.__calculate_inertia__(data, cluster, point)\n",
    "    self.point = self.__denormalize_point__(point, self.training_arr)\n",
    "    return cluster\n",
    "    \n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def get_cluster_centroid(self) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk mengambil point\n",
    "    '''\n",
    "    if type(self.point) == \"NoneType\":\n",
    "      print(\"Nothing returned, point not initialize. Try using fit_predict first.\")\n",
    "      return\n",
    "    return self.point\n",
    "  \n",
    "  \n",
    "  def __initialize_centroids__(self, data:np.array, k:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menginisialisasikan centroid. Menggunakan algoritma k-means++\n",
    "    referensi membantu: https://www.youtube.com/watch?v=HatwtJSsj5Q\n",
    "    '''\n",
    "    def _hitung_data_point_(num_process:int, data:np.array, centoids:np.array, return_dict:dict):\n",
    "      min_dist = []\n",
    "      for data_point in data:\n",
    "        distance_data_point = []\n",
    "        for point in centroids:\n",
    "          distance_data_point.append(np.sum(((data_point-point)**2)**0.5) )\n",
    "        min_dist.append(min(distance_data_point))\n",
    "      return_dict[num_process] = min_dist\n",
    "            \n",
    "    centroids = []\n",
    "    random.seed(1) # To get same random result for benchmark purposes\n",
    "    centroids.append( data[random.randrange(0, len(data))] )\n",
    "    \n",
    "    for i in range(1, k):\n",
    "      min_dist = []\n",
    "      data_split = np.array_split(data, os.cpu_count())\n",
    "      manager = mp.Manager()\n",
    "      return_dict = manager.dict()\n",
    "      processes = [mp.Process(target=_hitung_data_point_, args=(i, data_split[i], centroids, return_dict)) for i in range(len(data_split))]\n",
    "      for process in processes:\n",
    "        process.start()\n",
    "      for process in processes:\n",
    "        process.join()\n",
    "      min_dist = [return_dict[i] for i in sorted(return_dict)]\n",
    "      min_dist = np.concatenate((min_dist))\n",
    "      \n",
    "      probcum  = sum(min_dist)\n",
    "      prob_point = [value / probcum for value in min_dist]\n",
    "      \n",
    "      centroids.append(data[np.argmax(prob_point)])\n",
    "    \n",
    "    return np.array(centroids)\n",
    "  \n",
    "  \n",
    "  def __clustering__(self, distance: np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini akan mengembalikan hasil clustering berdasarkan distance\n",
    "    '''\n",
    "    cluster = np.zeros(len(distance))\n",
    "    for i in range(len(cluster)):\n",
    "      cluster[i] = np.argmin(distance[i])\n",
    "    return cluster\n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def __calculate_distance__(self, data:np.array, point: np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini akan menghitung setiap titik dengan point dan mengkembalikan jarak dari titik ke point\n",
    "    '''\n",
    "    # Setup penghitung\n",
    "    def _hitung_data_point_(num_process:int, data:np.array, point:np.array, return_dict):\n",
    "      distance = np.zeros((len(data), len(point)))\n",
    "      for i in range(len(data)):\n",
    "        current_record = data[i]\n",
    "        for j in range(len(point)):\n",
    "          current_point = point[j]\n",
    "          distance[i][j] = np.sum(((current_record-current_point)**2)**0.5)   \n",
    "      return_dict[num_process] = distance\n",
    "      \n",
    "    # Setup Processor dan bagi data\n",
    "    data_split = np.array_split(data, os.cpu_count())\n",
    "    manager = mp.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    processes = [mp.Process(target=_hitung_data_point_, args=(i, data_split[i], point, return_dict)) for i in range(len(data_split))]\n",
    "    \n",
    "    # Run on all the process\n",
    "    for process in processes:\n",
    "      process.start()\n",
    "    for process in processes:\n",
    "      process.join()\n",
    "    distance = [return_dict[i] for i in sorted(return_dict)]\n",
    "    distance = np.concatenate((distance))\n",
    "    return distance\n",
    "  \n",
    "  def __point_nomralization__(self, data:np.array, point:np.array, cluster:np.array) -> (np.array, np.array):\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menghitung ulang kembali point dengan rata-rata\n",
    "    '''\n",
    "    new_point = np.zeros((len(point), len(point[0])))\n",
    "    counter_array = np.zeros(len(point))\n",
    "    for i in range(len(cluster)):\n",
    "      new_point[int(cluster[i])] = new_point[int(cluster[i])] + data[i]\n",
    "      counter_array[int(cluster[i])] += 1\n",
    "      \n",
    "    unique_on_cluster = np.unique(cluster)\n",
    "    for i in range(len(point)):\n",
    "      # nan handling\n",
    "      if i not in unique_on_cluster:\n",
    "        new_point[i] = point[i]\n",
    "      else:\n",
    "        new_point[i] = np.true_divide(new_point[i], counter_array[i])\n",
    "      \n",
    "    return new_point\n",
    "  # Made by Kaenova Mahendra Auditama | 1301190324 | IF-43-02\n",
    "  def __convergence_check__(self, points1: np.array, points2:np.array, threshold: float) -> bool:\n",
    "    '''\n",
    "    Fungsi ini untuk mengecek convergence berdasarkan threshold yang dibuat.\n",
    "    titik cluster pertama akan dibandingkan dengan titik cluster kedua.\n",
    "    note: maybe i should use euclediance distance insted of menghitung satu-satu\n",
    "    '''\n",
    "    local_convergence = False\n",
    "    normalize_threshold_positive, normalize_threshold_negative  = 1 + threshold, 1 - threshold\n",
    "    points_counter = 0\n",
    "    center = np.zeros(len(points1[0]))\n",
    "    for i in range(len(points1)):\n",
    "      current_first_point, current_second_point = points1[i], points2[i]\n",
    "      distance_first_point, distance_second_point = np.sum(((current_first_point - center)**2)**0.5), np.sum(((current_second_point - center)**2)**0.5)\n",
    "      distance_threshold_positive = distance_first_point * normalize_threshold_positive\n",
    "      distance_threshold_negative = distance_first_point * normalize_threshold_negative\n",
    "      if distance_threshold_positive > distance_second_point and distance_threshold_negative < distance_second_point:\n",
    "        points_counter += 1\n",
    "    \n",
    "    if points_counter == len(points1):\n",
    "      local_convergence = True\n",
    "    \n",
    "    return local_convergence\n",
    "  \n",
    "  def __calculate_inertia__(self, data:np.array, cluster:np.array, points:np.array) -> np.array:\n",
    "    '''\n",
    "    K-Means: Inertia\n",
    "    Inertia measures how well a dataset was clustered by K-Means. It is calculated by measuring the distance between each data point and its centroid, squaring this distance, and summing these squares across one cluster.\n",
    "    ref: https://towardsdatascience.com/clustering-how-to-find-hyperparameters-using-inertia-b0343c6fe819\n",
    "    '''\n",
    "    inertia = 0\n",
    "    for i in range(len(data)):\n",
    "      inertia += np.sum(((data[i]-points[int(cluster[i])])**2)**0.5)**2      \n",
    "    return inertia\n",
    "  \n",
    "  def __normalize_data__(self, data:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk menormalisasikan data dengan menggunakan min-max scaling. Sehingga data berjenis dan bersatuan apapun data diproses dengan baik.\n",
    "    '''\n",
    "    data = data.copy()\n",
    "    for i in range(len(data[0])):\n",
    "      col_arr = data[:,i]\n",
    "      minmax = MinMaxScaler()\n",
    "      normalize = minmax.fit_transform(col_arr.reshape(-1,1)).reshape(1,-1)\n",
    "      data[:, i] = normalize[0]\n",
    "      \n",
    "    return data\n",
    "  \n",
    "  def __denormalize_point__(self, data:np.array, original_data:np.array) -> np.array:\n",
    "    '''\n",
    "    Fungsi ini digunakan untuk mendenormalisasikan point-point yang sudah dihitung menggunakan data yang ternormalisasi\n",
    "    '''\n",
    "    for i in range(len(data[0])):\n",
    "      col_arr = data[:,i]\n",
    "      col_arr_ori = original_data[:, i]\n",
    "      \n",
    "      minimums = min(col_arr_ori)\n",
    "      maximums = max(col_arr_ori)\n",
    "      for j in range(len(col_arr)):\n",
    "        col_arr[j] = ((col_arr[j]*(maximums - minimums)) + minimums)\n",
    "      data[:, i] = col_arr\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Umur</th>\n",
       "      <th>Kode_Daerah</th>\n",
       "      <th>Premi</th>\n",
       "      <th>Kanal_Penjualan</th>\n",
       "      <th>Lama_Berlangganan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28029.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>25800.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22735.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30786.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166391</th>\n",
       "      <td>285827</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25988.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166392</th>\n",
       "      <td>285828</td>\n",
       "      <td>21.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44686.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166393</th>\n",
       "      <td>285829</td>\n",
       "      <td>23.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49751.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166394</th>\n",
       "      <td>285830</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30503.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166395</th>\n",
       "      <td>285831</td>\n",
       "      <td>45.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36480.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166396 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Umur  Kode_Daerah    Premi  Kanal_Penjualan  Lama_Berlangganan\n",
       "0            1  30.0         33.0  28029.0            152.0               97.0\n",
       "1            2  48.0         39.0  25800.0             29.0              158.0\n",
       "2            4  58.0         48.0   2630.0            124.0               63.0\n",
       "3            6  21.0         35.0  22735.0            152.0              171.0\n",
       "4            9  20.0          8.0  30786.0            160.0               31.0\n",
       "...        ...   ...          ...      ...              ...                ...\n",
       "166391  285827  23.0          4.0  25988.0            152.0              217.0\n",
       "166392  285828  21.0         46.0  44686.0            152.0               50.0\n",
       "166393  285829  23.0         50.0  49751.0            152.0              226.0\n",
       "166394  285830  68.0          7.0  30503.0            124.0              270.0\n",
       "166395  285831  45.0         28.0  36480.0             26.0               44.0\n",
       "\n",
       "[166396 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = pd.read_csv(\"https://raw.githubusercontent.com/kaenova/Malin_Tubes1/main/data/processed/kendaraan_train_processed.csv\")\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_training.sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "==== K: 1 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "It's convergence!\n",
      "==== K: 2 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 3 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 4 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 5 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n"
     ]
    }
   ],
   "source": [
    "# No need to train again, i've already save the clusters\n",
    "# But if you want to try the training part, just uncomment this\n",
    "%load_ext line_profiler\n",
    "MAX_K = 5\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_run_history = {\n",
    "  \"data\" : \"2 Data Kanal Penjualan dan Umur\", \n",
    "  \"k_runs\" : {}\n",
    "}\n",
    "\n",
    "def run():\n",
    "    for i in range(1, MAX_K+1):\n",
    "      print(\"==== K:\", i, \"====\" )\n",
    "      run_data = {\n",
    "        \"points\" : None,\n",
    "        \"cluster\" : None,\n",
    "        \"inertia\" : None\n",
    "      }\n",
    "\n",
    "      model = KMeansBefore(df_training.filter(items=[\"Umur\",\"Kanal_Penjualan\"]))\n",
    "      run_data[\"cluster\"] = model.fit_predict(k_num=i, conv_threshold=1e-15, max_step=4)\n",
    "      run_data[\"inertia\"] = model.inertia\n",
    "      run_data[\"points\"] = model.point\n",
    "      data_run_history[\"k_runs\"][i] = run_data\n",
    "    \n",
    "%lprun -f KMeansBefore.fit_predict run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After Optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "==== K: 1 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "It's convergence!\n",
      "==== K: 2 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 3 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 4 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n",
      "==== K: 5 ====\n",
      "K-Means akan ditentukan oleh atribut-atribut di bawah ini:\n",
      "[Umur Kanal_Penjualan ]\n",
      "STEP: 1\n",
      "STEP: 2\n",
      "STEP: 3\n",
      "STEP: 4\n"
     ]
    }
   ],
   "source": [
    "# No need to train again, i've already save the clusters\n",
    "# But if you want to try the training part, just uncomment this\n",
    "%load_ext line_profiler\n",
    "MAX_K = 5\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_run_history = {\n",
    "  \"data\" : \"2 Data Kanal Penjualan dan Umur\", \n",
    "  \"k_runs\" : {}\n",
    "}\n",
    "\n",
    "def run():\n",
    "    for i in range(1, MAX_K+1):\n",
    "      print(\"==== K:\", i, \"====\" )\n",
    "      run_data = {\n",
    "        \"points\" : None,\n",
    "        \"cluster\" : None,\n",
    "        \"inertia\" : None\n",
    "      }\n",
    "\n",
    "      model = KMeans(df_training.filter(items=[\"Umur\",\"Kanal_Penjualan\"]))\n",
    "      run_data[\"cluster\"] = model.fit_predict(k_num=i, conv_threshold=1e-15, max_step=4)\n",
    "      run_data[\"inertia\"] = model.inertia\n",
    "      run_data[\"points\"] = model.point\n",
    "      data_run_history[\"k_runs\"][i] = run_data\n",
    "    \n",
    "%lprun -f KMeans.fit_predict run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
